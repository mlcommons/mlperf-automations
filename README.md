# MLPerf Automations and Scripts
[![License](https://img.shields.io/badge/License-Apache%202.0-green)](LICENSE.md)
[![Downloads](https://static.pepy.tech/badge/cm4mlops)](https://pepy.tech/project/cm4mlops)

[![CM script automation features test](https://github.com/mlcommons/mlperf-automations/actions/workflows/test-cm-script-features.yml/badge.svg)](https://github.com/mlcommons/mlperf-automations/actions/workflows/test-cm-script-features.yml)
[![MLPerf inference ABTF POC Test](https://github.com/mlcommons/mlperf-automations/actions/workflows/test-mlperf-inference-abtf-poc.yml/badge.svg)](https://github.com/mlcommons/mlperf-automations/actions/workflows/test-mlperf-inference-abtf-poc.yml)


This repository contains the automations and scripts used to run MLPerf benchmarks, primarily focusing on MLPerf inference benchmarks. The automations used here are largely based on and extended from the [Collective Mind script automations](https://github.com/mlcommons/cm4mlops/tree/main/automation/script).


## Collective Mind (CM) Automations

**CM (Collective Mind)** is a Python package with a CLI and API designed to create and manage automations. Two key automations developed using CM are **Script** and **Cache**, which streamline ML workflows, including managing Docker runs.

## Contributions
Please submit any pull requests (PRs) to dev branch. Please see [CONTRIBUTORS.md](here). For more information about using MLPerf Automations for MLPerf Inference, refer to the [MLPerf Inference Documentation](https://docs.mlcommons.org/inference/).

## News

* Waiting...

## License

[Apache 2.0](LICENSE.md)


## Funding

We thank OctoML(https://octoml.ai), [cKnowledge.org](https://cKnowledge.org), [cTuning foundation](https://cTuning.org) and [MLCommons](https://mlcommons.org) for sponsoring this project!

