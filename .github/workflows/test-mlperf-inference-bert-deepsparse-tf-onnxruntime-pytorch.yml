name: MLPerf inference bert (deepsparse, tf, onnxruntime, pytorch)

on:
  pull_request:
    branches: [ "main", "dev" ]
    paths:
      - '.github/workflows/test-mlperf-inference-bert-deepsparse-tf-onnxruntime-pytorch.yml'
      - '**'
      - '!**.md'

jobs:
  build:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        # 3.12 didn't work on 20240305 - need to check
        python-version: [ "3.11" ]
        backend: [ "deepsparse", "tf", "onnxruntime", "pytorch" ]
        precision: [ "int8", "fp32" ]
        os: [ubuntu-latest, windows-latest, macos-latest]
        exclude:
          - backend: tf
          - backend: pytorch
          - backend: onnxruntime
          - precision: fp32
          - os: windows-latest

    steps:
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install mlcflow
      run: |
        pip install mlcflow
        pip install tabulate
    - name: Pull MLOps repository
      run: |
        mlc pull repo ${{ github.event.pull_request.head.repo.html_url }} --branch=${{ github.event.pull_request.head.ref }}
    - name: Test MLPerf Inference Bert ${{ matrix.backend }} on ${{ matrix.os }}
      if: matrix.os == 'windows-latest'
      run: |
        mlcr --tags=run,mlperf,inference,generate-run-cmds,_submission,_short --submitter="MLCommons" --hw_name=gh_${{ matrix.os }} --model=bert-99 --backend=${{ matrix.backend }} --device=cpu --scenario=Offline --test_query_count=5 --adr.loadgen.tags=_from-pip --pip_loadgen=yes --precision=${{ matrix.precision }} --target_qps=1 -v --quiet
    - name: Test MLPerf Inference Bert ${{ matrix.backend }} on ${{ matrix.os }}
      if: matrix.os != 'windows-latest'
      run: |
        mlcr --tags=run,mlperf,inference,generate-run-cmds,_submission,_short --submitter="MLCommons" --hw_name=gh_${{ matrix.os }}_x86 --model=bert-99 --backend=${{ matrix.backend }} --device=cpu --scenario=Offline --test_query_count=5 --precision=${{ matrix.precision }} --target_qps=1 -v --quiet
    - name: Push Results
      if: github.repository_owner == 'gateoverflow'
      env:
          USER: "GitHub Action"
          EMAIL: "admin@gateoverflow.com"
          GITHUB_TOKEN: ${{ secrets.TEST_RESULTS_GITHUB_TOKEN }}
      run: |
        git config --global user.name "${{ env.USER }}"
        git config --global user.email "${{ env.EMAIL }}"
        git config --global credential.https://github.com.helper ""
        git config --global credential.https://github.com.helper "!gh auth git-credential"
        git config --global credential.https://gist.github.com.helper ""
        git config --global credential.https://gist.github.com.helper "!gh auth git-credential"
        mlcr --tags=push,github,mlperf,inference,submission --repo_url=https://github.com/mlcommons/mlperf_inference_test_submissions_v5.0 --repo_branch=dev --commit_message="Results from Bert GH action on ${{ matrix.os }}" --quiet
