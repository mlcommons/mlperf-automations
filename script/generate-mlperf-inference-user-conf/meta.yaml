# Identification of this CM script
alias: generate-mlperf-inference-user-conf
uid: 3af4475745964b93

automation_alias: script
automation_uid: 5b4e0237da074764

category: "MLPerf benchmark support"

developers: "[Arjun Suresh](https://www.linkedin.com/in/arjunsuresh), [Thomas Zhu](https://www.linkedin.com/in/hanwen-zhu-483614189), [Grigori Fursin](https://cKnowledge.org/gfursin)"

# User-friendly tags to find this CM script
tags:
  - generate
  - mlperf
  - inference
  - user-conf
  - inference-user-conf

# Default environment
default_env:
  MLC_MLPERF_LOADGEN_MODE: accuracy
  MLC_MLPERF_LOADGEN_SCENARIO: Offline
  MLC_OUTPUT_FOLDER_NAME: test_results
  MLC_MLPERF_RUN_STYLE: test
  MLC_TEST_QUERY_COUNT: '10'
  MLC_FAST_FACTOR: '5'
  MLC_MLPERF_QUANTIZATION: off
  MLC_MLPERF_RESULTS_DIR_SHARED: yes

docker:
  real_run: False

# Map script inputs to environment variables
input_mapping:
  count: MLC_MLPERF_LOADGEN_QUERY_COUNT
  hw_name: MLC_HW_NAME
  mode: MLC_MLPERF_LOADGEN_MODE
  num_threads: MLC_NUM_THREADS
  output_dir: OUTPUT_BASE_DIR
  power: MLC_MLPERF_POWER
  regenerate_files: MLC_REGENERATE_MEASURE_FILES
  rerun: MLC_RERUN
  scenario: MLC_MLPERF_LOADGEN_SCENARIO
  test_query_count: MLC_TEST_QUERY_COUNT
  target_qps: MLC_MLPERF_LOADGEN_TARGET_QPS
  target_latency: MLC_MLPERF_LOADGEN_TARGET_LATENCY
  offline_target_qps: MLC_MLPERF_LOADGEN_OFFLINE_TARGET_QPS
  server_target_qps: MLC_MLPERF_LOADGEN_SERVER_TARGET_QPS
  constantstream_target_qps: MLC_MLPERF_LOADGEN_CONSTANTSTREAM_TARGET_QPS
  singlestream_target_latency: MLC_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY
  multistream_target_latency: MLC_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY
  performance_sample_count: MLC_MLPERF_LOADGEN_PERFORMANCE_SAMPLE_COUNT

# Env keys which are exposed to higher level scripts
new_env_keys:
  - MLC_MLPERF_*
  - MLC_LOGS_DIR
  - MLC_HW_*
  - MLC_SUT_*
  - MLC_MAX_EXAMPLES

new_state_keys:
  - MLC_SUT_*

# Dependencies on other CM scripts
deps:

  # Detect host OS features
  - tags: detect,os

  # Detect host CPU features
  - tags: detect,cpu

  # Detect/install python
  - tags: get,python
    names:
    - python
    - python3

  - tags: get,mlperf,results,dir,local
    names:
      - get-mlperf-results-dir
    skip_if_env:
      OUTPUT_BASE_DIR:
        - "on"

  # Get SUT configs (System Under Test)
  - tags: get,sut,configs

variations:
  wg-inference:
    default: true
    group: benchmark_wg
    env:
      MLC_BENCHMARK_GROUP: inference
    deps:
      - tags: get,mlcommons,inference,src
        names:
        - inference-src
  wg-automotive:
    group: benchmark_wg
    env:
      MLC_BENCHMARK_GROUP: automotive
    deps:
      - tags: get,mlcommons,automotive,src
        names:
        - automotive-src