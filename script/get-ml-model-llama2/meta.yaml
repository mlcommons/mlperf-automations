alias: get-ml-model-llama2
automation_alias: script
automation_uid: 5b4e0237da074764
cache: true
category: AI/ML models
docker:
  real_run: false
env:
  MLC_ML_MODEL_DATASET: openorca
  MLC_ML_MODEL_WEIGHT_TRANSFORMATIONS: 'no'
input_mapping:
  checkpoint: LLAMA2_CHECKPOINT_PATH
new_env_keys:
- MLC_ML_MODEL_*
- LLAMA2_CHECKPOINT_PATH
- MLC_NVIDIA_TP_SIZE
- MLC_LLAMA2_FINAL_SAFE_TENSORS_PATH
prehook_deps:
- enable_if_env:
    MLC_TMP_REQUIRE_DOWNLOAD:
    - 'yes'
    MLC_DOWNLOAD_SRC:
    - 'huggingface'
  env: {}
  extra_cache_tags: llama2,llama-2
  force_env_keys:
  - MLC_GIT_CHECKOUT_FOLDER
  names:
  - hf-zoo
  tags: get,ml-model,huggingface,zoo,_clone-repo
  force_env_keys:
    - MLC_OUTDIRNAME  
print_env_at_the_end:
  LLAMA2_CHECKPOINT_PATH: LLAMA2 checkpoint path
tags:
- get
- raw
- ml-model
- language-processing
- llama2
- llama2-70b
- text-summarization
uid: 5db97be9f61244c6
variations:
  L40s:
    env:
      MLC_NVIDIA_TP_SIZE: 4
    group: gpu
  amd:
    default_env:
      MLC_LLAMA2_QUANTIZATION_DEVICE: ''
    default_variations:
      framework: pytorch
      precision: fp8
    env:
      MLC_TMP_ML_MODEL_PROVIDER: amd
    group: model-provider
    new_env_keys:
    - MLC_LLAMA2_FINAL_SAFE_TENSORS_ROOT
    - MLC_LLAMA2_FINAL_SAFE_TENSORS_PATH
  batch_size.#:
    env:
      MLC_ML_MODEL_BATCH_SIZE: '#'
  fp32:
    default: true
    env:
      MLC_ML_MODEL_INPUT_DATA_TYPES: fp32
      MLC_ML_MODEL_PRECISION: fp32
      MLC_ML_MODEL_WEIGHT_DATA_TYPES: fp32
    group: precision
  fp8:
    env:
      MLC_ML_MODEL_INPUT_DATA_TYPES: fp8
      MLC_ML_MODEL_PRECISION: fp8
      MLC_ML_MODEL_WEIGHT_DATA_TYPES: fp8
    group: precision
  generic:
    env:
      MLC_NVIDIA_TP_SIZE: 2
    group: gpu
  int8:
    env:
      MLC_ML_MODEL_INPUT_DATA_TYPES: int8
      MLC_ML_MODEL_PRECISION: int8
      MLC_ML_MODEL_WEIGHT_DATA_TYPES: int8
    group: precision
  mlc:
    group: download-source
    default: true
    env:
      MLC_DOWNLOAD_SRC: mlcommons
    prehook_deps:
      - tags: get,rclone-config,_mlperf-llama2
        force_cache: yes
  hf:
    group: download-source
    env:
      MLC_DOWNLOAD_SRC: huggingface
  70b:
    env:
      MLC_GIT_CHECKOUT_FOLDER: Llama-2-70b-chat-hf
    group: model-size
    default: true
    default_variations:
      huggingface-stub: meta-llama/Llama-2-70b-chat-hf
  7b:
    env:
      MLC_GIT_CHECKOUT_FOLDER: Llama-2-7b-chat-hf
    group: model-size    
    default_variations:
      huggingface-stub: meta-llama/Llama-2-7b-chat-hf

  70b-fused-qkv:
    env:
      MLC_GIT_CHECKOUT_FOLDER: Llama-2-70b-fused-qkv-mlperf
    group: model-size

  meta-llama/Llama-2-70b-chat-hf:
    base:
      - 70b
    adr:
      hf-zoo:
        tags: _model-stub.meta-llama/Llama-2-70b-chat-hf
    env:
      MLC_MODEL_ZOO_ENV_KEY: LLAMA2
    group: huggingface-stub

  meta-llama/Llama-2-7b-chat-hf:
    base:
      - 7b
    adr:
      hf-zoo:
        tags: _model-stub.meta-llama/Llama-2-7b-chat-hf
    env:
      MLC_MODEL_ZOO_ENV_KEY: LLAMA2
    group: huggingface-stub
  

  nvidia:
    default_variations:
      framework: pytorch
    env:
      MLC_TMP_ML_MODEL_PROVIDER: nvidia
    group: model-provider
  pytorch:
    default: true
    env:
      MLC_ML_MODEL_FRAMEWORK: pytorch
    group: framework
  pytorch,amd:
    default_variations:
      gpu: generic
      precision: fp8
    deps:
    - names:
      - python
      - python3
      tags: get,python3
    - env: {}
      force_new_env_keys:
      - LLAMA2_CHECKPOINT_PATH
      tags: get,ml-model,llama2-70b,_fp32,_pytorch
    - tags: get,preprocessed,dataset,openorca,_calibration,_mlc
    - env:
        MLC_GIT_CHECKOUT_PATH_ENV_NAME: MLC_MLPERF_INFERENCE_RESULTS_PATH
      extra_cache_tags: inference,results
      tags: get,git,repo,_repo.https://github.com/mlcommons/inference_results_v4.1,_branch.mlc-code-only
    - tags: get,generic-python-lib,_quark-amd
    - tags: get,generic-python-lib,_package.nltk
    - tags: get,generic-python-lib,_torch_cuda
    - tags: get,generic-python-lib,_package.compressed_tensors
  pytorch,fp32:
    env: {}
  pytorch,nvidia:
    default_variations:
      gpu: generic
      precision: fp8
    deps:
    - env:
        MLC_GIT_CHECKOUT_PATH_ENV_NAME: MLC_TENSORRT_LLM_CHECKOUT_PATH
      extra_cache_tags: tensorrt-llm
      tags: get,git,repo,_repo.https://github.com/NVIDIA/TensorRT-LLM.git,_sha.0ab9d17a59c284d2de36889832fe9fc7c8697604
    - names:
      - cuda
      tags: get,cuda
    - tags: get,nvidia,scratch,space
    - tags: get,cuda-devices,_with-pycuda
    - env: {}
      force_new_env_keys:
      - LLAMA2_CHECKPOINT_PATH
      tags: get,ml-model,llama2-70b,_fp32,_pytorch
    - names:
      - nvidia-inference-common-code
      tags: get,nvidia,inference,common-code
    - names:
      - python
      - python3
      tags: get,python3
  stub.#:
    adr:
      hf-zoo:
        tags: _model-stub.#
    env:
      MLC_MODEL_ZOO_ENV_KEY: LLAMA2
    group: huggingface-stub
  tp-size.#:
    env:
      MLC_NVIDIA_TP_SIZE: '#'
    group: gpu
  uint8:
    env:
      MLC_ML_MODEL_INPUT_DATA_TYPES: uint8
      MLC_ML_MODEL_PRECISION: uint8
      MLC_ML_MODEL_WEIGHT_DATA_TYPES: uint8
    group: precision
